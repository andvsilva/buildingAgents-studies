
---

# ğŸ§  12-Week AI Engineering Study Plan (Engineer Track)

â±ï¸ **Suggested load**: 10â€“15 h/week
ğŸ› ï¸ **Core stack**: Python, FastAPI, Docker, PyTorch, LLM APIs, Vector DBs

Below is a **12-week AI Engineering study plan** designed for **application-level mastery**, not academic theory.
It assumes:

* Strong **Python backend background**
* Goal: **build production-ready AI systems (LLMs, RAG, agents)**
* End result: **portfolio-grade AI engineering projects**

Each week includes **concepts, engineering skills, hands-on deliverables, and evaluation criteria**.


---

## ğŸ“… WEEK 1 â€” AI Engineering Foundations

### ğŸ¯ Objectives

* Understand what AI engineers build
* Differentiate ML research vs AI systems

### ğŸ“š Topics

* AI Engineering lifecycle
* LLMs vs classical ML
* Model-as-a-service
* Failure modes of AI systems

### ğŸ› ï¸ Hands-on

* Set up environment:

  * Python 3.11
  * venv / poetry
  * FastAPI
* Call LLM via API (OpenAI / local Ollama)

### ğŸ“¦ Deliverable

âœ” Minimal LLM-powered API endpoint

---

## ğŸ“… WEEK 2 â€” Math & ML Essentials (Engineer View)

### ğŸ¯ Objectives

* Understand math only where it affects systems

### ğŸ“š Topics

* Linear algebra for embeddings
* Probability & entropy
* Loss functions
* Gradient descent intuition

### ğŸ› ï¸ Hands-on

* Implement:

  * Cosine similarity
  * Simple SGD from scratch
* Visualize embeddings

### ğŸ“¦ Deliverable

âœ” Embedding similarity service

---

## ğŸ“… WEEK 3 â€” Self-Supervised Learning & Transformers

### ğŸ¯ Objectives

* Understand why LLMs work

### ğŸ“š Topics

* Self-supervised learning
* Transformer architecture
* Attention math
* Tokenization

### ğŸ› ï¸ Hands-on

* Implement attention in NumPy
* Train a tiny transformer on text

### ğŸ“¦ Deliverable

âœ” Mini transformer demo

---

## ğŸ“… WEEK 4 â€” Prompt Engineering as Software

### ğŸ¯ Objectives

* Treat prompts like production code

### ğŸ“š Topics

* Prompt patterns
* ReAct
* Chain-of-Thought
* Prompt injection

### ğŸ› ï¸ Hands-on

* Prompt versioning
* Prompt unit tests
* Deterministic outputs

### ğŸ“¦ Deliverable

âœ” Prompt test suite

---

## ğŸ“… WEEK 5 â€” Retrieval-Augmented Generation (RAG)

### ğŸ¯ Objectives

* Eliminate hallucinations
* Ground LLMs in data

### ğŸ“š Topics

* Embeddings
* Vector databases
* Chunking strategies
* Reranking

### ğŸ› ï¸ Hands-on

* Build RAG system:

  * FAISS
  * PDF ingestion
  * Query pipeline

### ğŸ“¦ Deliverable

âœ” RAG API (documents â†’ answers)

---

## ğŸ“… WEEK 6 â€” Evaluation & Observability

### ğŸ¯ Objectives

* Measure AI system quality

### ğŸ“š Topics

* Offline vs online eval
* Metrics for LLMs
* Cost tracking
* Drift detection

### ğŸ› ï¸ Hands-on

* Build evaluation harness
* Log prompts & outputs
* Token cost monitoring

### ğŸ“¦ Deliverable

âœ” AI evaluation dashboard

---

## ğŸ“… WEEK 7 â€” Multi-Agent Systems

### ğŸ¯ Objectives

* Move beyond single LLM calls

### ğŸ“š Topics

* Agent architectures
* Planning vs execution
* Agent communication
* Failure recovery

### ğŸ› ï¸ Hands-on

* Build agents:

  * Planner
  * Researcher
  * Critic
* Use LangGraph or custom orchestration

### ğŸ“¦ Deliverable

âœ” Multi-agent task solver

---

## ğŸ“… WEEK 8 â€” Tool Use & Function Calling

### ğŸ¯ Objectives

* Let LLMs interact with the real world

### ğŸ“š Topics

* Function calling
* Tool routing
* Validation
* Sandboxing

### ğŸ› ï¸ Hands-on

* LLM + tools:

  * DB queries
  * Python execution
* Secure tool access

### ğŸ“¦ Deliverable

âœ” Tool-using AI agent

---

## ğŸ“… WEEK 9 â€” Fine-Tuning & Adaptation

### ğŸ¯ Objectives

* Customize LLM behavior

### ğŸ“š Topics

* Fine-tuning vs prompting
* LoRA
* Embedding tuning
* Overfitting risks

### ğŸ› ï¸ Hands-on

* Fine-tune small model
* Compare with RAG

### ğŸ“¦ Deliverable

âœ” Adapted domain model

---

## ğŸ“… WEEK ğŸ”Ÿ â€” Deployment & Scaling

### ğŸ¯ Objectives

* Make AI systems production-ready

### ğŸ“š Topics

* FastAPI + async
* Docker
* Load balancing
* GPU vs CPU inference

### ğŸ› ï¸ Hands-on

* Dockerize AI service
* Add caching
* Stress test endpoints

### ğŸ“¦ Deliverable

âœ” Scalable AI API

---

## ğŸ“… WEEK 1ï¸âƒ£1ï¸âƒ£ â€” Safety, Security & Governance

### ğŸ¯ Objectives

* Prevent costly AI failures

### ğŸ“š Topics

* Prompt injection defense
* Bias detection
* Logging & audit
* Compliance (finance context)

### ğŸ› ï¸ Hands-on

* Input validation
* Safety filters
* Explainability logs

### ğŸ“¦ Deliverable

âœ” Secure AI system

---

## ğŸ“… WEEK 1ï¸âƒ£2ï¸âƒ£ â€” Capstone Project

### ğŸ¯ Objectives

* Demonstrate AI engineering mastery

### ğŸ› ï¸ Capstone Options

Choose one:

1ï¸âƒ£ **Multi-Agent Investment Assistant**
2ï¸âƒ£ **Enterprise Knowledge Copilot**
3ï¸âƒ£ **Autonomous Research Agent**

### ğŸ“¦ Final Deliverables

âœ” Architecture diagram
âœ” Codebase (clean & modular)
âœ” Evaluation report
âœ” Cost analysis

---

## ğŸ§ª Evaluation Criteria (Real-World)

| Category    | Measure              |
| ----------- | -------------------- |
| Reliability | Error rate           |
| Cost        | Tokens / request     |
| Latency     | P95 response         |
| Accuracy    | Eval scores          |
| Safety      | Injection resistance |

---

## ğŸš€ After 12 Weeks You Will Be Able To:

* Design AI system architectures
* Build multi-agent LLM systems
* Deploy scalable AI services
* Evaluate & optimize cost/performance
* Speak **AI engineering fluently** in interviews

---